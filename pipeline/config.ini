[Sieve_Selection]

# Set the sieves for the direct stw attribution here
# Write one sieve per line, they will be applied in the chosen order
# Set the selection to "optimal" if you want to apply the sieves 
# in the optimal order 
# Available sieves are:
# 	trigram_matching_sieve
#	loose_trigram_matching_sieve 
#	colon_sieve
#	dependency_sieve
#	loose_dependency_sieve
#	single_candidate_sieve
#	vocative_detection_sieve
#	binary_classifier_sieve 
#	conversational_sieve
#	loose_conversational_sieve
#	adjacent_quote_sieve
#	closest_candidate_sieve
direct = optimal 

# Set the sieves for the indirect stw speaker attribution here
# Available sieves are:
#	trigram_sieve_indirect
# 	dependency_sieve_indirect
#	loose_depencency_sieve_indirect
#	single_candidate_sieve_indirect
#	single_subject_sieve_indirect
#	single_verb_sieve
#       closest_verb_sieve
#	closest_candidate_sieve 
#	speech_verb_fall_back_sieve

indirect = optimal 

# The attribution of speaker for the reported stw units is divided 
# into the search for the speaker within the quote and outside the quote
# Set the sieves for the search within the quot here 
# Available sieves are:
# 	passive_sieve
#	stw_dependency_sieve
#	single_speech_noun_sieve
#	single_candidate_sieve_reported
#	single_subject_sieve_strict
#	stw_i_sieve
#	loose_stw_dependency_sieve
#	single_subject_sieve
#	speech_noun_genitive_object_sieve
#	single_candidate_sieve_reported

reported_in = optimal

# Set the sieves for the search outside the quote here
# Available sieves are:
#	single_subject_sieve
#	single_subject_sieve_strict
#	single_candidate_sieve_reported
#	closest_verb_sieve
#	closest_subject_sieve
#	dependency_sieve_reported
#	loose_depencency_sieve_reported

reported_out = optimal 

# Set the sieves for the free indirect stw speaker attribution here
# Available sieves are:
#	closest_speaking_candidate_strict
#	closest_candidate_sieve_before_strict
#	closest_candidate_sieve_before
#	loose_closest_candidate_sieve
#	question_sieve
#	neighbouring_instance_sieve

freeIndirect = optimal 

[ParZu]
# Tokenization, Lemmatization, PoS-Tagging and Dependency Parsing are performed with ParZu
# https://github.com/rsennrich/ParZu
# set the path to the ParZu parser here
ParZuPath = /Applications/ParZu/

[Ressources]
# Set filepaths to additional ressources here
# All files must be .txt files with one word per line
# 	- VerbList: must be a file of speech verbs 
# 	- MenschList must be a file with hyponyms of "Mensch"
#	- VocativeList must be a file with vocative words 

VerbList = ../resources/introductory_expressions/verb_cues.txt
MenschList = ../resources/animate_nouns/animate_nouns.txt
VocativeList = ../resources/vocatives/vocatives.txt
SpeechNounList = ../resources/introductory_expressions/speech_nouns.txt
FunctionalVerbList = ../resources/introductory_expressions/functional_verb_constructions.txt

[Classifier]
# Set filepaths to the binary classifiers for the different types of speech
# if the binary classification sieve shouldd be used
# You can train your own classifier, either with the implemented feature extraction
# or with your own feature extraction. If you use your own feature extraction you must
# change the code of the binary classifier sieves
direct = ../models/classifier_direct.pkl
indirect = ../models/classifier_indirect.pkl
reported_in = ../models/classifier_reported.pkl
